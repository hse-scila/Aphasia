{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.238277Z",
     "start_time": "2025-03-15T10:24:03.277824Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 13:36:03.318304: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-19 13:36:03.363183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-19 13:36:04.508180: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, balanced_accuracy_score, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scipy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "from src.utils import *\n",
    "\n",
    "from flaml import AutoML\n",
    "\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "from disvoice.prosody.prosody import Prosody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "787766693fdab936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.245396Z",
     "start_time": "2025-03-15T10:24:09.240198Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1984\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(SEED)\n",
    "\n",
    "SR = 8_000\n",
    "SEQUENCE_LENGTH = 300 * SR\n",
    "MFCC = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59d2322235479ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.255201Z",
     "start_time": "2025-03-15T10:24:09.246300Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "VOICES_DIR = os.path.join(DATA_DIR, 'Voices_wav')\n",
    "APHASIA_DIR = os.path.join(VOICES_DIR, 'Aphasia')\n",
    "NORM_DIR = os.path.join(VOICES_DIR, 'Norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03b516236c4f5a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.270417Z",
     "start_time": "2025-03-15T10:24:09.256461Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_DIR, 'train_filenames.csv'))\n",
    "val_data = pd.read_csv(os.path.join(DATA_DIR, 'val_filenames.csv'))\n",
    "test_data = pd.read_csv(os.path.join(DATA_DIR, 'test_filenames.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691f53a95991a38c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.287686Z",
     "start_time": "2025-03-15T10:24:09.271725Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data[\"file_name\"] = train_data.apply(lambda x: os.path.join(APHASIA_DIR, x['file_name']) if x['label'] == 1 else os.path.join(NORM_DIR, x['file_name']), axis=1)\n",
    "val_data[\"file_name\"] = val_data.apply(lambda x: os.path.join(APHASIA_DIR, x['file_name']) if x['label'] == 1 else os.path.join(NORM_DIR, x['file_name']), axis=1)\n",
    "test_data[\"file_name\"] = test_data.apply(lambda x: os.path.join(APHASIA_DIR, x['file_name']) if x['label'] == 1 else os.path.join(NORM_DIR, x['file_name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656c5fadb9901959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.316947Z",
     "start_time": "2025-03-15T10:24:09.288999Z"
    }
   },
   "outputs": [],
   "source": [
    "mfcc_class = torchaudio.transforms.MFCC(sample_rate=SR, n_mfcc=MFCC, log_mels=True, melkwargs={\"n_fft\": 20_000, \"win_length\": 10_000, \"hop_length\": 5_000, \"n_mels\": 200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f447214f65816546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.320077Z",
     "start_time": "2025-03-15T10:24:09.318020Z"
    }
   },
   "outputs": [],
   "source": [
    "chroma_stft_kwargs = {\"n_fft\": 20_000, \"win_length\": 10_000, \"hop_length\": 5_000, \"n_chroma\": 12}\n",
    "spectral_stft_kwargs = {\"n_fft\": 20_000, \"win_length\": 10_000, \"hop_length\": 5_000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2e02126b00423b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.334674Z",
     "start_time": "2025-03-15T10:24:09.320768Z"
    }
   },
   "outputs": [],
   "source": [
    "prosody = Prosody()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd9b352dfaaa426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.346093Z",
     "start_time": "2025-03-15T10:24:09.335330Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function_mfcc(path):\n",
    "    y, sr = librosa.load(path, sr=SR)\n",
    "    y = y[..., :SEQUENCE_LENGTH]\n",
    "    y = np.pad(y, (0, SEQUENCE_LENGTH - y.shape[0]), mode='constant')\n",
    "    mfcc = mfcc_class(torch.Tensor(y))\n",
    "\n",
    "    return mfcc.numpy().flatten().squeeze()\n",
    "\n",
    "def preprocess_function_chroma(path):\n",
    "    y, sr = librosa.load(path, sr=SR)\n",
    "    y = y[..., :SEQUENCE_LENGTH]\n",
    "    y = np.pad(y, (0, SEQUENCE_LENGTH - y.shape[0]), mode='constant')\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=SR, **chroma_stft_kwargs)\n",
    "\n",
    "    return chroma.flatten().squeeze()\n",
    "\n",
    "def preprocess_function_spectral(path):\n",
    "    y, sr = librosa.load(path, sr=SR)\n",
    "    y = y[..., :SEQUENCE_LENGTH]\n",
    "    y = np.pad(y, (0, SEQUENCE_LENGTH - y.shape[0]), mode='constant')\n",
    "    \n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr, **spectral_stft_kwargs)\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr, p=2, **spectral_stft_kwargs)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr, fmin=50, **spectral_stft_kwargs)\n",
    "    flatness = librosa.feature.spectral_flatness(y=y, **spectral_stft_kwargs)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, **spectral_stft_kwargs)\n",
    "\n",
    "    return np.hstack((centroid, bandwidth, contrast.flatten().squeeze()[None, ...], flatness, rolloff))\n",
    "\n",
    "def preprocess_function_zcr(path):\n",
    "    y, sr = librosa.load(path, sr=SR)\n",
    "    y = y[..., :SEQUENCE_LENGTH]\n",
    "    y = np.pad(y, (0, SEQUENCE_LENGTH - y.shape[0]), mode='constant')\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(y, frame_length=10_000, hop_length=5_000)\n",
    "    return zcr\n",
    "    \n",
    "def preprocess_function_simple(path):\n",
    "    y, sr = librosa.load(path, sr=SR)\n",
    "    y = y[..., :SEQUENCE_LENGTH]\n",
    "    y = np.pad(y, (0, SEQUENCE_LENGTH - y.shape[0]), mode='constant')\n",
    "    \n",
    "    speech_duration, speech_count, _, mean_speach_duration, silence_duration, duration_count, _, mean_silence_duration = get_speech_and_silence_timestamps(torch.Tensor(y), sr=SR)\n",
    "    return np.array([speech_duration, speech_count, mean_speach_duration, silence_duration, duration_count, mean_silence_duration, speech_duration / (silence_duration + 1e-6)])\n",
    "\n",
    "def preprocess_function_prosody(path):\n",
    "    features = prosody.prosody_static(path, plots=False)\n",
    "    \n",
    "    return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4154d58ef77bcb71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.361740Z",
     "start_time": "2025-03-15T10:24:09.347242Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(data_name, prep_function=None):\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, f\"train_data_{data_name}.npy\")) and not (prep_function is None):\n",
    "        _train_data = np.vstack((train_data[\"file_name\"].apply(prep_function)).to_numpy())\n",
    "        _val_data = np.vstack((val_data[\"file_name\"].apply(prep_function)).to_numpy())\n",
    "        _test_data = np.vstack((test_data[\"file_name\"].apply(prep_function)).to_numpy())\n",
    "    \n",
    "        np.save(os.path.join(DATA_DIR, f\"train_data_{data_name}.npy\"), _train_data)\n",
    "        np.save(os.path.join(DATA_DIR, f\"val_data_{data_name}.npy\"), _val_data)\n",
    "        np.save(os.path.join(DATA_DIR, f\"test_data_{data_name}.npy\"), _test_data)\n",
    "    else:\n",
    "        _train_data = np.load(os.path.join(DATA_DIR, f\"train_data_{data_name}.npy\"))\n",
    "        _val_data = np.load(os.path.join(DATA_DIR, f\"val_data_{data_name}.npy\"))\n",
    "        _test_data = np.load(os.path.join(DATA_DIR, f\"test_data_{data_name}.npy\"))\n",
    "    \n",
    "    return _train_data, _val_data, _test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657aab51281fd0bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.374434Z",
     "start_time": "2025-03-15T10:24:09.362543Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_prosody, val_data_prosody, test_data_prosody = get_features(\"prosody\", preprocess_function_prosody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e0d5d33cf089118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.504390Z",
     "start_time": "2025-03-15T10:24:09.375378Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_mfcc, val_data_mfcc, test_data_mfcc = get_features(\"mfcc\", preprocess_function_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "602fa477329f4ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.540825Z",
     "start_time": "2025-03-15T10:24:09.505256Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_chroma, val_data_chroma, test_data_chroma = get_features(\"chroma\", preprocess_function_chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edecf928852725a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.575257Z",
     "start_time": "2025-03-15T10:24:09.541540Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_spectral, val_data_spectral, test_data_spectral = get_features(\"spectral\", preprocess_function_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c466b18b072d7edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.584394Z",
     "start_time": "2025-03-15T10:24:09.576076Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_zrc, val_data_zrc, test_data_zrc = get_features(\"zrc\", preprocess_function_zcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1541760ecb5aa63a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.590385Z",
     "start_time": "2025-03-15T10:24:09.585337Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_simple, val_data_simple, test_data_simple = get_features(\"simple\", preprocess_function_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45a63c5648734032",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.857066Z",
     "start_time": "2025-03-15T10:24:09.591471Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all_features = np.hstack((train_data_mfcc, train_data_chroma, train_data_spectral, train_data_simple, train_data_zrc, train_data_prosody))\n",
    "val_all_features = np.hstack((val_data_mfcc, val_data_chroma, val_data_spectral, val_data_simple, val_data_zrc, val_data_prosody))\n",
    "test_all_features = np.hstack((test_data_mfcc, test_data_chroma, test_data_spectral, test_data_simple, test_data_zrc, test_data_prosody))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aadbcfcb435d4dab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.942336Z",
     "start_time": "2025-03-15T10:24:09.858155Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_mfcc = np.hstack((train_data_mfcc, train_data_zrc))\n",
    "val_data_mfcc = np.hstack((val_data_mfcc, val_data_zrc))\n",
    "test_data_mfcc = np.hstack((test_data_mfcc, test_data_zrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11ed33185c8372eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.957757Z",
     "start_time": "2025-03-15T10:24:09.943164Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_chroma = np.hstack((train_data_chroma, train_data_zrc))\n",
    "val_data_chroma = np.hstack((val_data_chroma, val_data_zrc))\n",
    "test_data_chroma = np.hstack((test_data_chroma, test_data_zrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ff23bd0c79953e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.972773Z",
     "start_time": "2025-03-15T10:24:09.959025Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_spectral = np.hstack((train_data_spectral, train_data_zrc))\n",
    "val_data_spectral = np.hstack((val_data_spectral, val_data_zrc))\n",
    "test_data_spectral = np.hstack((test_data_spectral, test_data_zrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4935a54f78a9bd5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:09.976886Z",
     "start_time": "2025-03-15T10:24:09.973773Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_simple = np.hstack((train_data_simple, train_data_zrc))\n",
    "val_data_simple = np.hstack((val_data_simple, val_data_zrc))\n",
    "test_data_simple = np.hstack((test_data_simple, test_data_zrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35956a7629321d18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:43.859335Z",
     "start_time": "2025-03-15T10:24:43.856258Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_prosody = np.hstack((train_data_prosody, train_data_zrc))\n",
    "val_data_prosody = np.hstack((val_data_prosody, val_data_zrc))\n",
    "test_data_prosody = np.hstack((test_data_prosody, test_data_zrc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13c21a29f447a441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:24:44.325516Z",
     "start_time": "2025-03-15T10:24:44.322245Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_balanced_accuracy(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    estimator,\n",
    "    labels,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    weight_val=None,\n",
    "    weight_train=None,\n",
    "    *args,\n",
    "):\n",
    "    start = time.time()\n",
    "    y_pred = estimator.predict_proba(X_val)\n",
    "    pred_time = (time.time() - start) / len(X_val)\n",
    "    val_acc = balanced_accuracy_score(y_val, np.argmax(y_pred, axis=-1), sample_weight=weight_val)\n",
    "    return 1 - val_acc, {\n",
    "        \"val_acc\": val_acc,\n",
    "        \"pred_time\": pred_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d124bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_participant(model, features):\n",
    "    test_data_ids = pd.concat([test_data, pd.DataFrame(features)], axis=1)\n",
    "    test_data_ids[\"ID\"] = test_data_ids[\"file_name\"].apply(lambda x: str(x).split(\"/\")[-1].split(\"-\")[0] + str(x).split(\"/\")[-1].split(\"-\")[1])\n",
    "    IDs = test_data_ids[\"ID\"].unique()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for participant_id in tqdm(IDs):\n",
    "        participant_samples = test_data_ids[test_data_ids[\"ID\"] == participant_id]\n",
    "        labels = participant_samples[\"label\"]\n",
    "        features = participant_samples.iloc[:, 2:-1]\n",
    "\n",
    "        pred = np.argmax(model.predict_proba(features.values).mean(axis=0))\n",
    "\n",
    "        all_preds.append(pred)\n",
    "\n",
    "        all_labels.append(labels.values[0])\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2756c265bf5b925",
   "metadata": {},
   "source": [
    "## Prosody features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "278a9a768e300d24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:40:35.691405Z",
     "start_time": "2025-03-15T10:24:45.420825Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_prosody, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_prosody, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_prosody = AutoML()\n",
    "automl_prosody.fit(train_data_prosody, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_prosody, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bac3f4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_prosody.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcef87612fabd94c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:40:35.720783Z",
     "start_time": "2025-03-15T10:40:35.693540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.69        42\n",
      "           1       0.88      0.96      0.92       130\n",
      "\n",
      "    accuracy                           0.87       172\n",
      "   macro avg       0.86      0.78      0.81       172\n",
      "weighted avg       0.87      0.87      0.86       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_prosody.predict(test_data_prosody) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94a73335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/72 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 1092.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79        21\n",
      "           1       0.89      0.96      0.92        51\n",
      "\n",
      "    accuracy                           0.89        72\n",
      "   macro avg       0.89      0.84      0.86        72\n",
      "weighted avg       0.89      0.89      0.89        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_prosody, test_data_prosody)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cdc693ad87084",
   "metadata": {},
   "source": [
    "## MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b6982573fe8cf55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:57:07.916283Z",
     "start_time": "2025-03-15T10:40:35.722173Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_mfcc, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_mfcc, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_mfcc = AutoML()\n",
    "automl_mfcc.fit(train_data_mfcc, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_mfcc, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bb7b6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lgbm'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_mfcc.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ca870a34d3af271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T10:57:07.940036Z",
     "start_time": "2025-03-15T10:57:07.917473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71        42\n",
      "           1       0.90      0.93      0.91       130\n",
      "\n",
      "    accuracy                           0.87       172\n",
      "   macro avg       0.83      0.80      0.81       172\n",
      "weighted avg       0.86      0.87      0.86       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_mfcc.predict(test_data_mfcc) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45c46ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:05<00:00, 14.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72        21\n",
      "           1       0.86      0.96      0.91        51\n",
      "\n",
      "    accuracy                           0.86        72\n",
      "   macro avg       0.86      0.79      0.81        72\n",
      "weighted avg       0.86      0.86      0.85        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_mfcc, test_data_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540e91f062e8997",
   "metadata": {},
   "source": [
    "## Chroma features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "501d8ed929e8c385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T11:12:59.812141Z",
     "start_time": "2025-03-15T10:57:07.941244Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_chroma, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_chroma, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_chroma = AutoML()\n",
    "automl_chroma.fit(train_data_chroma, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_chroma, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a9fd678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb_limitdepth'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_chroma.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12a48303b7090157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T11:12:59.842474Z",
     "start_time": "2025-03-15T11:12:59.813323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.62        42\n",
      "           1       0.87      0.90      0.89       130\n",
      "\n",
      "    accuracy                           0.83       172\n",
      "   macro avg       0.77      0.75      0.76       172\n",
      "weighted avg       0.82      0.83      0.82       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_chroma.predict(test_data_chroma) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2e11276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 1074.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72        21\n",
      "           1       0.86      0.96      0.91        51\n",
      "\n",
      "    accuracy                           0.86        72\n",
      "   macro avg       0.86      0.79      0.81        72\n",
      "weighted avg       0.86      0.86      0.85        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_chroma, test_data_chroma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9bf1714950f092",
   "metadata": {},
   "source": [
    "## Spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e60bcf586d9fe63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T11:29:23.588440Z",
     "start_time": "2025-03-15T11:12:59.843760Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_spectral, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_spectral, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_spectral = AutoML()\n",
    "automl_spectral.fit(train_data_spectral, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_spectral, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2752ada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extra_tree'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_spectral.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80456cd4ccff5d92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T11:29:23.623253Z",
     "start_time": "2025-03-15T11:29:23.590744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.52      0.57        42\n",
      "           1       0.85      0.90      0.88       130\n",
      "\n",
      "    accuracy                           0.81       172\n",
      "   macro avg       0.74      0.71      0.72       172\n",
      "weighted avg       0.80      0.81      0.80       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_spectral.predict(test_data_spectral) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8adbb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:01<00:00, 52.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.43      0.53        21\n",
      "           1       0.80      0.92      0.85        51\n",
      "\n",
      "    accuracy                           0.78        72\n",
      "   macro avg       0.74      0.68      0.69        72\n",
      "weighted avg       0.77      0.78      0.76        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_spectral, test_data_spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e45d12d522863c",
   "metadata": {},
   "source": [
    "## Simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f42d7576566c8b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T11:45:13.734380Z",
     "start_time": "2025-03-15T11:29:23.624394Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_simple, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_simple, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_simple = AutoML()\n",
    "automl_simple.fit(train_data_simple, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_simple, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f90b0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb_limitdepth'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_simple.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98ec3171b662cfcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T11:45:13.766276Z",
     "start_time": "2025-03-15T11:45:13.737443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.45      0.52        42\n",
      "           1       0.84      0.91      0.87       130\n",
      "\n",
      "    accuracy                           0.80       172\n",
      "   macro avg       0.72      0.68      0.70       172\n",
      "weighted avg       0.78      0.80      0.79       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_simple.predict(test_data_simple) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "590b1ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 1380.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72        21\n",
      "           1       0.86      0.96      0.91        51\n",
      "\n",
      "    accuracy                           0.86        72\n",
      "   macro avg       0.86      0.79      0.81        72\n",
      "weighted avg       0.86      0.86      0.85        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_simple, test_data_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b92e218e32d189",
   "metadata": {},
   "source": [
    "## All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f57d9263daec1a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:01:52.396585Z",
     "start_time": "2025-03-15T11:45:13.767459Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_all_features, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_all_features, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_all_features = AutoML()\n",
    "automl_all_features.fit(train_all_features, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_all_features, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5e87acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_all_features.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b529debe9ad0aa36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:01:52.507916Z",
     "start_time": "2025-03-15T12:01:52.399498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.69        42\n",
      "           1       0.88      0.96      0.92       130\n",
      "\n",
      "    accuracy                           0.87       172\n",
      "   macro avg       0.86      0.78      0.81       172\n",
      "weighted avg       0.87      0.87      0.86       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_all_features.predict(test_all_features) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f80c171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 524.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        21\n",
      "           1       0.88      1.00      0.94        51\n",
      "\n",
      "    accuracy                           0.90        72\n",
      "   macro avg       0.94      0.83      0.87        72\n",
      "weighted avg       0.91      0.90      0.90        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_all_features, test_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded36ec8ed2afd30",
   "metadata": {},
   "source": [
    "## Simple + MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7fe2ac504c365e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:01:52.607426Z",
     "start_time": "2025-03-15T12:01:52.510274Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all_features = np.hstack((train_data_mfcc[:, :-1], train_data_simple))\n",
    "val_all_features = np.hstack((val_data_mfcc[:, :-1], val_data_simple))\n",
    "test_all_features = np.hstack((test_data_mfcc[:, :-1], test_data_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2513a83f1d0f2a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:18:18.315358Z",
     "start_time": "2025-03-15T12:01:52.608659Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_all_features, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_all_features, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_all_features = AutoML()\n",
    "automl_all_features.fit(train_all_features, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_all_features, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73b25df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lgbm'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_all_features.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b6d4fb2987ef3c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:18:18.349001Z",
     "start_time": "2025-03-15T12:18:18.326228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68        42\n",
      "           1       0.88      0.94      0.91       130\n",
      "\n",
      "    accuracy                           0.86       172\n",
      "   macro avg       0.82      0.78      0.80       172\n",
      "weighted avg       0.85      0.86      0.86       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_all_features.predict(test_all_features) \n",
    "\n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b4d1cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:05<00:00, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.57      0.71        21\n",
      "           1       0.85      0.98      0.91        51\n",
      "\n",
      "    accuracy                           0.86        72\n",
      "   macro avg       0.89      0.78      0.81        72\n",
      "weighted avg       0.87      0.86      0.85        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report_participant(automl_all_features, test_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc4f96c6c4eaee",
   "metadata": {},
   "source": [
    "## Experiments with wav2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce5234b3fc071f53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:18:19.197966Z",
     "start_time": "2025-03-15T12:18:18.350201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781e56309ee44b0188a0ab2050325e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2359fc4150d2471194d4a6d4d655e2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\", sampling_rate=SR, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a63598660030a41e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:18:19.207193Z",
     "start_time": "2025-03-15T12:18:19.201011Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function_wav2vec(path):\n",
    "    y, sr = librosa.load(path, sr=SR)\n",
    "    y = y[..., :SEQUENCE_LENGTH]\n",
    "    y = np.pad(y, (0, SEQUENCE_LENGTH - y.shape[0]), mode='constant')\n",
    "    \n",
    "    inputs = feature_extractor(\n",
    "        torch.tensor(y), sampling_rate=feature_extractor.sampling_rate, max_length=4_000, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    # print(inputs)\n",
    "    return inputs['input_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8eb5524779000afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:18:22.666459Z",
     "start_time": "2025-03-15T12:18:19.208712Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_wav2vec = np.vstack(train_data[\"file_name\"].apply(preprocess_function_wav2vec))\n",
    "val_data_wav2vec = np.vstack(val_data[\"file_name\"].apply(preprocess_function_wav2vec))\n",
    "test_data_wav2vec = np.vstack(test_data[\"file_name\"].apply(preprocess_function_wav2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ca7ce8f98417a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:34:12.542679Z",
     "start_time": "2025-03-15T12:18:22.667766Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_wav2vec, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_wav2vec, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_wav2vec = AutoML()\n",
    "automl_wav2vec.fit(train_data_wav2vec, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_wav2vec, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11e6706caf6f6719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:34:12.583889Z",
     "start_time": "2025-03-15T12:34:12.553782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.52      0.59        42\n",
      "           1       0.86      0.92      0.88       130\n",
      "\n",
      "    accuracy                           0.82       172\n",
      "   macro avg       0.76      0.72      0.74       172\n",
      "weighted avg       0.81      0.82      0.81       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_wav2vec.predict(test_data_wav2vec) \n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425ea137563b05c",
   "metadata": {},
   "source": [
    "## Wav2vec with PCA (for some reason....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fb1e77c4593526f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:34:12.592050Z",
     "start_time": "2025-03-15T12:34:12.585298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 472)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_wav2vec.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82a7c74188ac937c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:34:14.321995Z",
     "start_time": "2025-03-15T12:34:12.593672Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=250)\n",
    "\n",
    "train_data_wav2vec_pca = pca.fit_transform(train_data_wav2vec)\n",
    "val_data_wav2vec_pca = pca.transform(val_data_wav2vec)\n",
    "test_data_wav2vec_pca = pca.transform(test_data_wav2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba4d1410d06c0444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:50:04.889407Z",
     "start_time": "2025-03-15T12:34:14.323235Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_automl = AutoML()\n",
    "pre_automl.fit(train_data_wav2vec_pca, train_data[\"label\"], task=\"classification\", time_budget=150, X_val=val_data_wav2vec_pca, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], verbose=False)\n",
    "\n",
    "automl_wav2vec_pca = AutoML()\n",
    "automl_wav2vec_pca.fit(train_data_wav2vec_pca, train_data[\"label\"], task=\"classification\", time_budget=800, X_val=val_data_wav2vec_pca, y_val=val_data[\"label\"], metric=custom_balanced_accuracy, seed=SEED, estimator_list=['lgbm', 'xgboost', 'xgb_limitdepth', 'rf', 'extra_tree', 'catboost'], starting_points=pre_automl.best_config_per_estimator, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82be9e8515418700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:50:04.920851Z",
     "start_time": "2025-03-15T12:50:04.899468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.43      0.52        42\n",
      "           1       0.83      0.93      0.88       130\n",
      "\n",
      "    accuracy                           0.81       172\n",
      "   macro avg       0.75      0.68      0.70       172\n",
      "weighted avg       0.79      0.81      0.79       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = automl_wav2vec_pca.predict(test_data_wav2vec_pca) \n",
    "print(classification_report(test_data[\"label\"], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789810188db36b67",
   "metadata": {},
   "source": [
    "## Meta classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "486aaa780056cf01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:50:04.949968Z",
     "start_time": "2025-03-15T12:50:04.921725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>31735</th>\n",
       "      <th>31736</th>\n",
       "      <th>31737</th>\n",
       "      <th>31738</th>\n",
       "      <th>31739</th>\n",
       "      <th>31740</th>\n",
       "      <th>31741</th>\n",
       "      <th>31742</th>\n",
       "      <th>31743</th>\n",
       "      <th>31744</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-133.220810</td>\n",
       "      <td>-86.438217</td>\n",
       "      <td>-50.233150</td>\n",
       "      <td>2.749326</td>\n",
       "      <td>-67.728760</td>\n",
       "      <td>-75.160988</td>\n",
       "      <td>-42.209667</td>\n",
       "      <td>-38.456062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-127.859444</td>\n",
       "      <td>-57.902290</td>\n",
       "      <td>4.641314</td>\n",
       "      <td>19.603796</td>\n",
       "      <td>38.635742</td>\n",
       "      <td>42.423389</td>\n",
       "      <td>42.932121</td>\n",
       "      <td>39.175602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-133.322495</td>\n",
       "      <td>-91.622047</td>\n",
       "      <td>-31.579760</td>\n",
       "      <td>-27.227444</td>\n",
       "      <td>26.310484</td>\n",
       "      <td>67.676003</td>\n",
       "      <td>48.572411</td>\n",
       "      <td>-63.792099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-133.801498</td>\n",
       "      <td>-88.440720</td>\n",
       "      <td>-59.631699</td>\n",
       "      <td>-19.610685</td>\n",
       "      <td>-25.806852</td>\n",
       "      <td>48.195946</td>\n",
       "      <td>70.444359</td>\n",
       "      <td>26.359131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-132.111694</td>\n",
       "      <td>-78.014793</td>\n",
       "      <td>-81.933823</td>\n",
       "      <td>-88.991348</td>\n",
       "      <td>-93.623466</td>\n",
       "      <td>-76.771866</td>\n",
       "      <td>-21.169638</td>\n",
       "      <td>-0.507260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31747 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  label           0  \\\n",
       "0  /home/zakhar/aphasia_classification/data/Voice...      0 -133.220810   \n",
       "1  /home/zakhar/aphasia_classification/data/Voice...      0 -127.859444   \n",
       "2  /home/zakhar/aphasia_classification/data/Voice...      0 -133.322495   \n",
       "3  /home/zakhar/aphasia_classification/data/Voice...      0 -133.801498   \n",
       "4  /home/zakhar/aphasia_classification/data/Voice...      0 -132.111694   \n",
       "\n",
       "           1          2          3          4          5          6  \\\n",
       "0 -86.438217 -50.233150   2.749326 -67.728760 -75.160988 -42.209667   \n",
       "1 -57.902290   4.641314  19.603796  38.635742  42.423389  42.932121   \n",
       "2 -91.622047 -31.579760 -27.227444  26.310484  67.676003  48.572411   \n",
       "3 -88.440720 -59.631699 -19.610685 -25.806852  48.195946  70.444359   \n",
       "4 -78.014793 -81.933823 -88.991348 -93.623466 -76.771866 -21.169638   \n",
       "\n",
       "           7  ...  31735  31736  31737  31738  31739  31740  31741  31742  \\\n",
       "0 -38.456062  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  39.175602  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2 -63.792099  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  26.359131  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  -0.507260  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   31743  31744  \n",
       "0    0.0    0.0  \n",
       "1    0.0    0.0  \n",
       "2    0.0    0.0  \n",
       "3    0.0    0.0  \n",
       "4    0.0    0.0  \n",
       "\n",
       "[5 rows x 31747 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_mfcc = pd.concat([test_data, pd.DataFrame(test_data_mfcc)], axis=1)\n",
    "test_data_mfcc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5310384fea178f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:50:04.962364Z",
     "start_time": "2025-03-15T12:50:04.950791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>31736</th>\n",
       "      <th>31737</th>\n",
       "      <th>31738</th>\n",
       "      <th>31739</th>\n",
       "      <th>31740</th>\n",
       "      <th>31741</th>\n",
       "      <th>31742</th>\n",
       "      <th>31743</th>\n",
       "      <th>31744</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-133.220810</td>\n",
       "      <td>-86.438217</td>\n",
       "      <td>-50.233150</td>\n",
       "      <td>2.749326</td>\n",
       "      <td>-67.728760</td>\n",
       "      <td>-75.160988</td>\n",
       "      <td>-42.209667</td>\n",
       "      <td>-38.456062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-127.859444</td>\n",
       "      <td>-57.902290</td>\n",
       "      <td>4.641314</td>\n",
       "      <td>19.603796</td>\n",
       "      <td>38.635742</td>\n",
       "      <td>42.423389</td>\n",
       "      <td>42.932121</td>\n",
       "      <td>39.175602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-133.322495</td>\n",
       "      <td>-91.622047</td>\n",
       "      <td>-31.579760</td>\n",
       "      <td>-27.227444</td>\n",
       "      <td>26.310484</td>\n",
       "      <td>67.676003</td>\n",
       "      <td>48.572411</td>\n",
       "      <td>-63.792099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-133.801498</td>\n",
       "      <td>-88.440720</td>\n",
       "      <td>-59.631699</td>\n",
       "      <td>-19.610685</td>\n",
       "      <td>-25.806852</td>\n",
       "      <td>48.195946</td>\n",
       "      <td>70.444359</td>\n",
       "      <td>26.359131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "      <td>0</td>\n",
       "      <td>-132.111694</td>\n",
       "      <td>-78.014793</td>\n",
       "      <td>-81.933823</td>\n",
       "      <td>-88.991348</td>\n",
       "      <td>-93.623466</td>\n",
       "      <td>-76.771866</td>\n",
       "      <td>-21.169638</td>\n",
       "      <td>-0.507260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/zakhar/aphasia_classification/data/Voice...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  label           0  \\\n",
       "0  /home/zakhar/aphasia_classification/data/Voice...      0 -133.220810   \n",
       "1  /home/zakhar/aphasia_classification/data/Voice...      0 -127.859444   \n",
       "2  /home/zakhar/aphasia_classification/data/Voice...      0 -133.322495   \n",
       "3  /home/zakhar/aphasia_classification/data/Voice...      0 -133.801498   \n",
       "4  /home/zakhar/aphasia_classification/data/Voice...      0 -132.111694   \n",
       "\n",
       "           1          2          3          4          5          6  \\\n",
       "0 -86.438217 -50.233150   2.749326 -67.728760 -75.160988 -42.209667   \n",
       "1 -57.902290   4.641314  19.603796  38.635742  42.423389  42.932121   \n",
       "2 -91.622047 -31.579760 -27.227444  26.310484  67.676003  48.572411   \n",
       "3 -88.440720 -59.631699 -19.610685 -25.806852  48.195946  70.444359   \n",
       "4 -78.014793 -81.933823 -88.991348 -93.623466 -76.771866 -21.169638   \n",
       "\n",
       "           7  ...  31736  31737  31738  31739  31740  31741  31742  31743  \\\n",
       "0 -38.456062  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  39.175602  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2 -63.792099  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  26.359131  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  -0.507260  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   31744                                                 ID  \n",
       "0    0.0  /home/zakhar/aphasia_classification/data/Voice...  \n",
       "1    0.0  /home/zakhar/aphasia_classification/data/Voice...  \n",
       "2    0.0  /home/zakhar/aphasia_classification/data/Voice...  \n",
       "3    0.0  /home/zakhar/aphasia_classification/data/Voice...  \n",
       "4    0.0  /home/zakhar/aphasia_classification/data/Voice...  \n",
       "\n",
       "[5 rows x 31748 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_mfcc[\"ID\"] = test_data_mfcc[\"file_name\"].apply(lambda x: str(x).split(\"-\")[0] + str(x).split(\"-\")[1])\n",
    "test_data_mfcc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c6ddb8b033f40",
   "metadata": {},
   "source": [
    "Here we simply changed the metric. Since most patients have several audio recordings, we decided to predict the patient's class rather than the class of each recording. (We get predictions for all audio and take the mode of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ce66a75458621af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T12:50:05.266800Z",
     "start_time": "2025-03-15T12:50:04.963427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:05<00:00, 13.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        21\n",
      "           1       0.92      0.92      0.92        51\n",
      "\n",
      "    accuracy                           0.89        72\n",
      "   macro avg       0.87      0.87      0.87        72\n",
      "weighted avg       0.89      0.89      0.89        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IDs = test_data_mfcc[\"ID\"].unique()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for participant_id in tqdm(IDs):\n",
    "    participant_samples = test_data_mfcc[test_data_mfcc[\"ID\"] == participant_id]\n",
    "    labels = participant_samples[\"label\"]\n",
    "    features = participant_samples.iloc[:, 2:-1]\n",
    "\n",
    "    pred = scipy.stats.mode(automl_mfcc.predict(features.values))\n",
    "\n",
    "    all_preds.append(pred.mode)\n",
    "\n",
    "    all_labels.append(labels.values[0])\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9402e9cb2cfa4158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:07:45.998181Z",
     "start_time": "2025-03-15T13:07:45.993540Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_prosody = pd.concat([test_data, pd.DataFrame(test_data_prosody)], axis=1)\n",
    "test_data_prosody[\"ID\"] = test_data_prosody[\"file_name\"].apply(lambda x: str(x).split(\"-\")[0] + str(x).split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14ee38db754a9ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T13:08:15.001836Z",
     "start_time": "2025-03-15T13:08:14.693802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 864.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79        21\n",
      "           1       0.89      0.96      0.92        51\n",
      "\n",
      "    accuracy                           0.89        72\n",
      "   macro avg       0.89      0.84      0.86        72\n",
      "weighted avg       0.89      0.89      0.89        72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IDs = test_data_prosody[\"ID\"].unique()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for participant_id in tqdm(IDs):\n",
    "    participant_samples = test_data_prosody[test_data_prosody[\"ID\"] == participant_id]\n",
    "    labels = participant_samples[\"label\"]\n",
    "    features = participant_samples.iloc[:, 2:-1]\n",
    "\n",
    "    pred = scipy.stats.mode(automl_prosody.predict(features.values))\n",
    "\n",
    "    all_preds.append(pred.mode)\n",
    "\n",
    "    all_labels.append(labels.values[0])\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5c417cef93b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aphasia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
